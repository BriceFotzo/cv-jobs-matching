{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Job 1 - Score 51.02 %\n",
      "Infos Data Scientist\n",
      "NTICO Technology\n",
      "Lille, Hauts-de-France, France\n",
      "----------------------------------------------------------------------------\n",
      "Job 2 - Score 60.2 %\n",
      "Infos Data Scientist\n",
      "Groupe Caisse des Dépôts\n",
      "Paris, Île-de-France, France\n",
      "----------------------------------------------------------------------------\n",
      "Job 3 - Score 61.43 %\n",
      "Infos Data Scientist\n",
      "La Banque Postale\n",
      "Paris, Île-de-France, France\n",
      "----------------------------------------------------------------------------\n",
      "Job 4 - Score 8.41 %\n",
      "Infos Data Scientist\n",
      "Datadog\n",
      "Paris, Île-de-France, France\n",
      "----------------------------------------------------------------------------\n",
      "Job 5 - Score 48.5 %\n",
      "Infos Data Scientist-(H/F)\n",
      "Société Générale\n",
      "Fontenay-sous-Bois, Île-de-France, France\n",
      "----------------------------------------------------------------------------\n",
      "Job 6 - Score 9.99 %\n",
      "Infos Data Scientist\n",
      "AKUR8\n",
      "Ville de Paris, Île-de-France, France\n",
      "----------------------------------------------------------------------------\n",
      "Job 7 - Score 57.78 %\n",
      "Infos Data Scientist\n",
      "Socio Data Management\n",
      "Paris et périphérie\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common import keys\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from heapq import nlargest\n",
    "import en_core_web_sm\n",
    "import fr_core_news_sm\n",
    "# Import summarize from gensim\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords# Import the library\n",
    "# to convert MSword doc to txt for processing.\n",
    "import docx2txt\n",
    "nlp_job = fr_core_news_sm.load()\n",
    "nlp_resume=fr_core_news_sm.load()\n",
    "from dotenv import load_dotenv,dotenv_values\n",
    "from getpass import getpass\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "\n",
    "\n",
    "def get_jobs_links(job_query,user,pwd):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        job_query ([type]): [description]\n",
    "    \"\"\"\n",
    "    browser=webdriver.Chrome(\"chromedriver.exe\")\n",
    "    browser.get(\"https://www.linkedin.com\")\n",
    "\n",
    "    username=browser.find_element_by_id(\"session_key\")\n",
    "    username.send_keys(user)\n",
    "    password=browser.find_element_by_id(\"session_password\")\n",
    "    password.send_keys(pwd)\n",
    "\n",
    "    login_button=browser.find_element_by_class_name(\"sign-in-form__submit-button\")\n",
    "    login_button.click()\n",
    "\n",
    "    browser.get(job_query)\n",
    "    sleep(3)\n",
    "    jobs=browser.find_elements_by_class_name(\"job-card-container\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    jobs_links=[]\n",
    "    jobs_head=[]\n",
    "    for i in jobs:\n",
    "        jobs_links.append(i.find_elements_by_tag_name('a')[0].get_attribute('href'))\n",
    "        jobs_head.append(i.find_element_by_class_name(\"artdeco-entity-lockup__content\").text)\n",
    "    return browser,jobs_links,jobs_head\n",
    "\n",
    "\n",
    "def scrape_job(browser,job_link):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    browser.get(job_link)\n",
    "    sleep(3)\n",
    "    more_button=browser.find_element_by_class_name(\"artdeco-card__action\")\n",
    "    more_button.click()\n",
    "    sleep(3)\n",
    "    content=browser.find_elements_by_class_name('jobs-box__html-content')[0].text\n",
    "    # print(content)\n",
    "    return content\n",
    "\n",
    "def get_keywords_from_job(job_description):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        job_description ([type]): [description]\n",
    "    \"\"\"\n",
    "    keyword = []\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "    for token in job_description:\n",
    "        if(token.text in stopwords or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            keyword.append(token.text)\n",
    "    return keyword\n",
    "            \n",
    "def get_n_common_words(keywords,n):\n",
    "    freq_word = Counter(keywords)\n",
    "    print(freq_word.most_common(n))    \n",
    "    return freq_word   \n",
    "\n",
    "def get_sent_strength(freq_word):\n",
    "    sent_strength={}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text in freq_word.keys():\n",
    "                if sent in sent_strength.keys():\n",
    "                    sent_strength[sent]+=freq_word[word.text]\n",
    "                else:\n",
    "                    sent_strength[sent]=freq_word[word.text]\n",
    "    print(sent_strength)\n",
    "    return sent_strength\n",
    "def summurize_sent(sent_strength,ratio=3):\n",
    "    summarized_sentences = nlargest(ratio, sent_strength, key=sent_strength.get)\n",
    "    # print(summarized_sentences)\n",
    "    final_sentences = [ w.text for w in summarized_sentences ]\n",
    "    summary = ' '.join(final_sentences)\n",
    "    # print(summary)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def match_resume_and_job(job_description, resume,head,i):\n",
    "    text_list = [job_description, resume]\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cv = CountVectorizer()\n",
    "    count_matrix = cv.fit_transform(text_list)\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # get the match percentage\n",
    "    matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "    matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "    print(\"Job {} - Score {} %\".format(i,str(matchPercentage)))\n",
    "    print(\"Infos\",head)\n",
    "    # print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    # print(keywords(job_description, ratio=0.25)) \n",
    "    # gives you the keywords of the job description\n",
    "from urllib.parse import quote\n",
    " \n",
    "\n",
    "def matching_pipeline(job_link,user,pwd,resume_path):\n",
    "    resume_content = docx2txt.process(\"CV_Brice_FOTZO.docx\")\n",
    "    browser,links,heads=get_jobs_links(job_link,user,pwd)\n",
    "    sleep(3)\n",
    "    cpt=1\n",
    "    for head,job in zip(heads,links):\n",
    "        job_content=scrape_job(browser,job)\n",
    "        match_resume_and_job(job_content,resume_content,head,cpt)\n",
    "        cpt=cpt+1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    userN=input(\"Email/Nom d'utilisateur : \")\n",
    "    pswd=getpass(\"Mot de passe : \")\n",
    "    job_query_online = input(\"Enter Job description : \")\n",
    "    keyword_job=quote(job_query_online)\n",
    "    jobs=\"https://www.linkedin.com/jobs/search/?keywords=\"+keyword_job+\"&location=France\"\n",
    "    matching_pipeline(job_link=jobs,user=userN,pwd=pswd,resume_path=\"CV_Brice_FOTZO.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}