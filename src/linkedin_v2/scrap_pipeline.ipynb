{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ab67d360d69a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mkeyword_job\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_query_online\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://www.linkedin.com/jobs/search/?keywords=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mkeyword_job\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&location=France\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[0mmatching_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_link\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muserN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpswd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresume_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"CV_Brice_FOTZO.docx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-ab67d360d69a>\u001b[0m in \u001b[0;36mmatching_pipeline\u001b[1;34m(job_link, user, pwd, resume_path)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0mfeatures_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;31m# print(\"Job {} - Score {} %\".format(i,str(matchPercentage)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common import keys\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from heapq import nlargest\n",
    "import en_core_web_sm\n",
    "import fr_core_news_sm\n",
    "# Import summarize from gensim\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords# Import the library\n",
    "# to convert MSword doc to txt for processing.\n",
    "import docx2txt\n",
    "nlp_job = fr_core_news_sm.load()\n",
    "nlp_resume=fr_core_news_sm.load()\n",
    "from dotenv import load_dotenv,dotenv_values\n",
    "from getpass import getpass\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "\n",
    "\n",
    "def get_jobs_links(job_query,user,pwd):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        job_query ([type]): [description]\n",
    "    \"\"\"\n",
    "    browser=webdriver.Chrome(\"chromedriver.exe\")\n",
    "    browser.get(\"https://www.linkedin.com\")\n",
    "\n",
    "    username=browser.find_element_by_id(\"session_key\")\n",
    "    username.send_keys(user)\n",
    "    password=browser.find_element_by_id(\"session_password\")\n",
    "    password.send_keys(pwd)\n",
    "\n",
    "    login_button=browser.find_element_by_class_name(\"sign-in-form__submit-button\")\n",
    "    login_button.click()\n",
    "\n",
    "    browser.get(job_query)\n",
    "    sleep(3)\n",
    "    jobs=browser.find_elements_by_class_name(\"job-card-container\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    jobs_links=[]\n",
    "    jobs_head=[]\n",
    "    for i in jobs:\n",
    "        jobs_links.append(i.find_elements_by_tag_name('a')[0].get_attribute('href'))\n",
    "        jobs_head.append(i.find_element_by_class_name(\"artdeco-entity-lockup__content\").text)\n",
    "    return browser,jobs_links,jobs_head\n",
    "\n",
    "\n",
    "def scrape_job(browser,job_link):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    browser.get(job_link)\n",
    "    sleep(3)\n",
    "    more_button=browser.find_element_by_class_name(\"artdeco-card__action\")\n",
    "    more_button.click()\n",
    "    sleep(3)\n",
    "    content=browser.find_elements_by_class_name('jobs-box__html-content')[0].text\n",
    "    # print(content)\n",
    "    return content\n",
    "\n",
    "def get_keywords_from_job(job_description):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        job_description ([type]): [description]\n",
    "    \"\"\"\n",
    "    keyword = []\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "    for token in job_description:\n",
    "        if(token.text in stopwords or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            keyword.append(token.text)\n",
    "    return keyword\n",
    "            \n",
    "def get_n_common_words(keywords,n):\n",
    "    freq_word = Counter(keywords)\n",
    "    print(freq_word.most_common(n))    \n",
    "    return freq_word   \n",
    "\n",
    "def get_sent_strength(freq_word):\n",
    "    sent_strength={}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text in freq_word.keys():\n",
    "                if sent in sent_strength.keys():\n",
    "                    sent_strength[sent]+=freq_word[word.text]\n",
    "                else:\n",
    "                    sent_strength[sent]=freq_word[word.text]\n",
    "    print(sent_strength)\n",
    "    return sent_strength\n",
    "def summurize_sent(sent_strength,ratio=3):\n",
    "    summarized_sentences = nlargest(ratio, sent_strength, key=sent_strength.get)\n",
    "    # print(summarized_sentences)\n",
    "    final_sentences = [ w.text for w in summarized_sentences ]\n",
    "    summary = ' '.join(final_sentences)\n",
    "    # print(summary)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def match_resume_and_job(job_description, resume,head,i):\n",
    "    text_list = [job_description, resume]\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cv = CountVectorizer()\n",
    "    count_matrix = cv.fit_transform(text_list)\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # get the match percentage\n",
    "    matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "    matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "    # print(keywords(job_description, ratio=0.25)) \n",
    "    # gives you the keywords of the job description\n",
    "    return head, matchPercentage\n",
    "from urllib.parse import quote\n",
    " \n",
    "\n",
    "def matching_pipeline(job_link,user,pwd,resume_path):\n",
    "    resume_content = docx2txt.process(\"CV_Brice_FOTZO.docx\")\n",
    "    browser,links,heads=get_jobs_links(job_link,user,pwd)\n",
    "    sleep(3)\n",
    "    cpt=1\n",
    "    features=[]\n",
    "    for head,job in zip(heads,links):\n",
    "        job_content=scrape_job(browser,job)\n",
    "        score=match_resume_and_job(job_content,resume_content,head,cpt)[1]\n",
    "        cpt=cpt+1\n",
    "        features.append({\"head\":head,\"score\":score})\n",
    "\n",
    "\n",
    "    features_sorted=sorted(features, key=lambda kv: kv['score'])\n",
    "    print(features_sorted)\n",
    "    # print(\"Job {} - Score {} %\".format(i,str(matchPercentage)))\n",
    "    # print(\"Infos\",head)\n",
    "    # # print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")\n",
    "    # print(\"----------------------------------------------------------------------------\")\n",
    "if __name__==\"__main__\":\n",
    "    userN=input(\"Email/Nom d'utilisateur : \")\n",
    "    pswd=getpass(\"Mot de passe : \")\n",
    "    job_query_online = input(\"Enter Job description : \")\n",
    "    keyword_job=quote(job_query_online)\n",
    "    jobs=\"https://www.linkedin.com/jobs/search/?keywords=\"+keyword_job+\"&location=France\"\n",
    "    matching_pipeline(job_link=jobs,user=userN,pwd=pswd,resume_path=\"CV_Brice_FOTZO.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}